{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3d45df7",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "Suppose we have a bunch of URLs and we want to know their adult-rating\n",
    "(i.e., is the url P, or G, or X, or R). This task is difficult for\n",
    "computers, but easy for humans, and this has led to the growth of\n",
    "crowdsourcing: get a bunch of humans to give ratings to urls, but\n",
    "use automated techniques to figure out how much to trust each person's\n",
    "ratings.\n",
    "\n",
    "We are going to use the data from a paper by Ipeirotis *et al.*\n",
    "This details an experiment run on Amazon's *Mechanical Turk* crowdsourcing system.\n",
    "They ask a bunch of raters (called \"turks\") to rate several urls,\n",
    "but they already know the answers (the true categories) for a few\n",
    "urls, called the **gold set**. The ratings of the turks on the gold\n",
    "set thus allows us to judge their accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99e23f6",
   "metadata": {},
   "source": [
    "### [Q1 10 points] Read in data}\n",
    "Read in the files **gold.txt** and **labels.txt**.  The **gold**\n",
    "DataFrame should have columns `url` and `category`, while the\n",
    "**labels** DataFrame should have columns `turk`, `url` and\n",
    "`category`. You will have to pick the right separator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f264d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "994d75d3",
   "metadata": {},
   "source": [
    "### [Q2 10 points] Split into two DataFrames\n",
    "Split the **labels** DataFrame into two:\n",
    "* **labels_on_gold**, containing all rows where the url is present in the gold set, and\n",
    "* **labels_unknown**, containing all the remaining rows of **labels**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab0f95a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e21d2ba",
   "metadata": {},
   "source": [
    "### [Q3 10 points] Compute accuracies of turks\n",
    "Create a **rater_goodness** DataFrame that is indexed by turk, and\n",
    "has two columns: the number of ratings, and the average correctness of\n",
    "ratings for each turk (both on gold set urls)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1bc74c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f65f0083",
   "metadata": {},
   "source": [
    "### [Q4 10 points] Odds ratios}\n",
    "If someone is correct $p$ fraction of the time, the `odds` of\n",
    "success are defined as:\n",
    "\n",
    "$$\\mbox{odds} = \\frac{p}{1.001-p}.$$\n",
    "\n",
    "Attach a column called `odds` to the **rater_goodness** DataFrame, using the average correctness of the turk as his or her $p$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fccb720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2f3a5ad",
   "metadata": {},
   "source": [
    "### [Q5 10 points] Most accurate turks\n",
    "List the top 10 most accurate turks who have rated at least 20 gold set URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57d7b0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc7e0fb7",
   "metadata": {},
   "source": [
    "### [Q6 10 points] Rating counts versus accuracy\n",
    "One may imagine that a committed and accurate turk will rate lots of\n",
    "URLs. On the other hand, perhaps it is only the spammers who have the\n",
    "time to rate lots of URLs.\n",
    "\n",
    "Is number of ratings by a turker on gold set URLs related to his or\n",
    "her accuracy? There's no fixed answer; just try to show some evidence\n",
    "for your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa5a4f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9dd63979",
   "metadata": {},
   "source": [
    "### [Q7 13 points] Overall predicted odds}\n",
    "\n",
    "Let $u$ denote any url $u$ that is *not* in the gold set, and let $c$ denote some category. \n",
    "\n",
    "* For every valid pair $(u, c)$, calculate the product of odds of all turks who satisfy the following two conditions: \n",
    "    1. the turk rated url $u$ as category $c$, and \n",
    "    2. he/she rated more gold set urls than 75% of all turks who rated at least one gold-set url.\n",
    "\n",
    "For example, if you find that there are 269 turks who rated at least\n",
    "one gold-set url, you want to select only the turks who have rated\n",
    "more gold-set urls than 75% of these 269 turks. We can think of\n",
    "these as our *\"reliable\"* turks. Now, our belief that url $u$ belongs\n",
    "to category $c$ depends on how many reliable turks rated $u$ as $c$;\n",
    "specifically, our belief is based on the product of their reliability\n",
    "scores (i.e., their odds).\n",
    "\n",
    "We shall call such products of odds the **overall odds** henceforth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9212a0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9665c4ff",
   "metadata": {},
   "source": [
    "### [Q8 13 points] Predicted categories\n",
    "Create a DataFrame called **result_75**, with the following characteristics:\n",
    "* its index is URLs not in the gold set,\n",
    "* it has two columns:\n",
    "    * `top category`: the category with the highest overall odds for that url, and\n",
    "    * `top odds`: the overall odds for that top category.\n",
    "\n",
    "These are our predictions, and the confidence we have in them (higher\n",
    "overall odds implies greater confidence). If you want, you can\n",
    "check to see if the predicted categories make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee11638",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b5b7ff9",
   "metadata": {},
   "source": [
    "### [Q9 14 points] Predicted categories using more turks\n",
    "Questions 7 and 8 above only considered the ratings of turks who had\n",
    "rated enough gold set URLs, so we were relatively more confident about\n",
    "their accuracies. What happens if we loosen this restriction?\n",
    "\n",
    "Repeat the code of Q7 and Q8, but replacing 75% by 25% in the description of Q7 (i.e., we also consider turks who have far fewer gold set ratings).\n",
    "Call this **result_25**.\n",
    "\n",
    "Now let's see how these two results compare. \n",
    "Create a DataFrame where both the index and the columns are the\n",
    "various categories, and the cells contain the number of urls with\n",
    "these as the top categories according to **result_75** and **result_25**.\n",
    "\n",
    "For example, the cell corresponding to the row `category=R`\n",
    "and the column `category=G` would be the number of URLs that were predicted to\n",
    "be *R* by **result_75** but predicted to be *G* by **result_25**.\n",
    "\n",
    "Where are the most errors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640837a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
